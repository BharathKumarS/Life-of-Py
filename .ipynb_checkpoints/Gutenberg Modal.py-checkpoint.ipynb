{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gutenbern corpus with NLTK package\n",
    "### Step 1: Download and Install Gutenberg Corpus\n",
    "\n",
    "    Install NLTK: run sudo pip install -U nltk\n",
    "    Install Numpy (optional): run sudo pip install -U numpy\n",
    "    Test installation: run python then type import nltk\n",
    "\n",
    "### Step 2: Import source data from the package NLTK\n",
    "#### The Brown Corpus was the first million-word electronic corpus of English, created in 1961 at Brown University. This corpus contains text from 500 sources, and the sources have been categorized by genre, such as news, editorial, and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk as NLTK\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "cats = brown.categories()\n",
    "print(cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Relative Frequency distributionand conditional frequency of modals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency Distribution of modals \n",
      "\n",
      "can: 94 could: 87 may: 93 might: 38 will: 389 would: 246 should: 61 "
     ]
    }
   ],
   "source": [
    "#Frequency Distribution\n",
    "text = brown.words(categories='news')\n",
    "fdist = NLTK.FreqDist(w.lower() for w in text)\n",
    "modals = ['can', 'could', 'may', 'might', 'will', 'would', 'should']\n",
    "print('Frequency Distribution of modals \\n')\n",
    "for mods in modals:\n",
    "    print(mods + ':', fdist[mods], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional frequency Distribution for modals across all genres\n",
      "\n",
      "                   can  could    may  might   will  would should \n",
      "      adventure     46    151      5     58     50    191     15 \n",
      " belles_lettres    246    213    207    113    236    392    102 \n",
      "      editorial    121     56     74     39    233    180     88 \n",
      "        fiction     37    166      8     44     52    287     35 \n",
      "     government    117     38    153     13    244    120    112 \n",
      "        hobbies    268     58    131     22    264     78     73 \n",
      "          humor     16     30      8      8     13     56      7 \n",
      "        learned    365    159    324    128    340    319    171 \n",
      "           lore    170    141    165     49    175    186     76 \n",
      "        mystery     42    141     13     57     20    186     29 \n",
      "           news     93     86     66     38    389    244     59 \n",
      "       religion     82     59     78     12     71     68     45 \n",
      "        reviews     45     40     45     26     58     47     18 \n",
      "        romance     74    193     11     51     43    244     32 \n",
      "science_fiction     16     49      4     12     16     79      3 \n"
     ]
    }
   ],
   "source": [
    "cFrqDist = NLTK.ConditionalFreqDist((genre, word)\n",
    "                               for genre in brown.categories()\n",
    "                               for word in brown.words(categories=genre))\n",
    "genres = cats\n",
    "print('Conditional frequency Distribution for modals across all genres\\n')\n",
    "cFrqDist.tabulate(conditions=genres, samples=modals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inaugural corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import inaugural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1789-Washington.txt', '1793-Washington.txt', '1797-Adams.txt', '1801-Jefferson.txt', '1805-Jefferson.txt', '1809-Madison.txt', '1813-Madison.txt', '1817-Monroe.txt', '1821-Monroe.txt', '1825-Adams.txt', '1829-Jackson.txt', '1833-Jackson.txt', '1837-VanBuren.txt', '1841-Harrison.txt', '1845-Polk.txt', '1849-Taylor.txt', '1853-Pierce.txt', '1857-Buchanan.txt', '1861-Lincoln.txt', '1865-Lincoln.txt', '1869-Grant.txt', '1873-Grant.txt', '1877-Hayes.txt', '1881-Garfield.txt', '1885-Cleveland.txt', '1889-Harrison.txt', '1893-Cleveland.txt', '1897-McKinley.txt', '1901-McKinley.txt', '1905-Roosevelt.txt', '1909-Taft.txt', '1913-Wilson.txt', '1917-Wilson.txt', '1921-Harding.txt', '1925-Coolidge.txt', '1929-Hoover.txt', '1933-Roosevelt.txt', '1937-Roosevelt.txt', '1941-Roosevelt.txt', '1945-Roosevelt.txt', '1949-Truman.txt', '1953-Eisenhower.txt', '1957-Eisenhower.txt', '1961-Kennedy.txt', '1965-Johnson.txt', '1969-Nixon.txt', '1973-Nixon.txt', '1977-Carter.txt', '1981-Reagan.txt', '1985-Reagan.txt', '1989-Bush.txt', '1993-Clinton.txt', '1997-Clinton.txt', '2001-Bush.txt', '2005-Bush.txt', '2009-Obama.txt', '2013-Obama.txt', '2017-Trump.txt']\n"
     ]
    }
   ],
   "source": [
    "inaguralCats = inaugural.fileids()\n",
    "print(inaguralCats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/raam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "NLTK.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inauguralText = inaugural.words(fileids='1789-Washington.txt')\n",
    "inauguralText = [word for word in inauguralText if word not in stopwords.words('english') \n",
    "                 and word.isalpha() == True \n",
    "                 and len(word) > 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('government', 73), ('national', 72), ('administration', 62), ('expected', 40), ('received', 33), ('department', 32), ('possible', 29), ('together', 27), ('republican', 26), ('question', 22), ('resolution', 21), ('necessary', 18), ('executive', 18), ('official', 17), ('security', 17), ('effective', 15), ('important', 14), ('decision', 13), ('addition', 12), ('considered', 12), ('personal', 12), ('citizens', 11), ('required', 11), ('included', 11), ('advantage', 10), ('ordinary', 9), ('conflict', 8), ('constitutional', 8), ('therefore', 8), ('advanced', 7), ('established', 7), ('attention', 7), ('sufficient', 6), ('confidence', 6), ('resulted', 6), ('compared', 6), ('governments', 6), ('recommendations', 6), ('experience', 6), ('produced', 6), ('essential', 5), ('employed', 5), ('voluntary', 5), ('circumstances', 5), ('entering', 5), ('prospect', 5), ('judgment', 5), ('summoned', 4), ('experienced', 4), ('consulted', 4), ('independent', 4), ('accomplished', 4), ('communities', 4), ('thinking', 4), ('recommend', 4), ('particular', 4), ('selected', 4), ('separate', 4), ('foundation', 4), ('benefits', 4), ('compensation', 4), ('estimates', 4), ('occasion', 4), ('difficulty', 3), ('scrutiny', 3), ('repaired', 3), ('purposes', 3), ('influence', 3), ('establishing', 3), ('principles', 3), ('instance', 3), ('incident', 2), ('inclination', 2), ('frequent', 2), ('qualifications', 2), ('endowments', 2), ('appreciation', 2), ('instances', 2), ('originated', 2), ('allotted', 2), ('character', 2), ('distinguished', 2), ('strongly', 2), ('proceedings', 2), ('measures', 2), ('expedient', 2), ('substitute', 2), ('interests', 2), ('satisfaction', 2), ('submitted', 2), ('characteristic', 2), ('sufficiently', 2), ('addressed', 2), ('struggle', 2), ('provision', 2), ('continuance', 2), ('flattering', 1), ('rendered', 1), ('inheriting', 1), ('inferior', 1), ('conscious', 1), ('deficiencies', 1), ('affected', 1), ('grateful', 1), ('consequences', 1), ('impressions', 1), ('improper', 1), ('presides', 1), ('councils', 1), ('instituted', 1), ('instrument', 1), ('functions', 1), ('expresses', 1), ('acknowledge', 1), ('conducts', 1), ('deliberations', 1), ('suppressed', 1), ('auspiciously', 1), ('assembled', 1), ('congenial', 1), ('feelings', 1), ('recommendation', 1), ('characters', 1), ('comprehensive', 1), ('assemblage', 1), ('morality', 1), ('thoroughly', 1), ('prosperity', 1), ('ordained', 1), ('preservation', 1), ('experiment', 1), ('exercise', 1), ('occasional', 1), ('opportunities', 1), ('carefully', 1), ('observations', 1), ('properly', 1), ('concerns', 1), ('departed', 1), ('permanent', 1), ('expenditures', 1), ('unanimity', 1), ('conspicuous', 1), ('enlarged', 1), ('temperate', 1), ('consultations', 1), ('Citizens', 0), ('Representatives', 0), ('vicissitudes', 0), ('anxieties', 0), ('notification', 0), ('transmitted', 0), ('veneration', 0), ('predilection', 0), ('immutable', 0), ('declining', 0), ('interruptions', 0), ('committed', 0), ('magnitude', 0), ('distrustful', 0), ('overwhelm', 0), ('despondence', 0), ('unpracticed', 0), ('peculiarly', 0), ('emotions', 0), ('faithful', 0), ('circumstance', 0), ('executing', 0), ('remembrance', 0), ('affectionate', 0), ('sensibility', 0), ('transcendent', 0), ('incapacity', 0), ('disinclination', 0), ('palliated', 0), ('partiality', 0), ('obedience', 0), ('supplications', 0), ('Almighty', 0), ('universe', 0), ('providential', 0), ('benediction', 0), ('consecrate', 0), ('liberties', 0), ('happiness', 0), ('Government', 0), ('tendering', 0), ('sentiments', 0), ('Invisible', 0), ('revolution', 0), ('tranquil', 0), ('distinct', 0), ('gratitude', 0), ('anticipation', 0), ('blessings', 0), ('reflections', 0), ('commence', 0), ('President', 0), ('consideration', 0), ('defining', 0), ('designates', 0), ('consistent', 0), ('rectitude', 0), ('patriotism', 0), ('honorable', 0), ('prejudices', 0), ('attachments', 0), ('animosities', 0), ('misdirect', 0), ('preeminence', 0), ('exemplified', 0), ('attributes', 0), ('affections', 0), ('indissoluble', 0), ('magnanimous', 0), ('felicity', 0), ('persuaded', 0), ('propitious', 0), ('disregards', 0), ('entrusted', 0), ('American', 0), ('delegated', 0), ('Constitution', 0), ('juncture', 0), ('objections', 0), ('inquietude', 0), ('undertaking', 0), ('discernment', 0), ('alteration', 0), ('endanger', 0), ('reverence', 0), ('impregnably', 0), ('fortified', 0), ('advantageously', 0), ('promoted', 0), ('foregoing', 0), ('contemplated', 0), ('renounce', 0), ('pecuniary', 0), ('inapplicable', 0), ('emoluments', 0), ('indispensably', 0), ('accordingly', 0), ('imparted', 0), ('awakened', 0), ('resorting', 0), ('supplication', 0), ('deliberating', 0), ('tranquillity', 0), ('dispositions', 0), ('deciding', 0), ('unparalleled', 0), ('advancement', 0), ('blessing', 0)]\n"
     ]
    }
   ],
   "source": [
    "topTen = dict()\n",
    "for word in inauguralText:\n",
    "    topTen[word] = fdist[word]\n",
    "\n",
    "try:\n",
    "    topTen = sorted(topTen.items(), key=lambda x: x[1], reverse = True)\n",
    "    print(topTen)\n",
    "except:\n",
    "    topTen = dict()\n",
    "    for word in inauguralText:\n",
    "        topTen[word] = fdist[word]\n",
    "    topTen = sorted(topTen.items(), key=lambda x: x[1], reverse = True)\n",
    "    print(topTen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency Distribution of Top 10 words whose character length in > 7 \n",
      "\n",
      "government: 8 \n",
      " national: 1 \n",
      " administration: 2 \n",
      " expected: 1 \n",
      " received: 1 \n",
      " department: 2 \n",
      " possible: 1 \n",
      " together: 1 \n",
      " republican: 1 \n",
      " question: 1 \n",
      " "
     ]
    }
   ],
   "source": [
    "inauguralFDist = NLTK.FreqDist(inTxt.lower() for inTxt in inauguralText)\n",
    "topWords = ['government', 'national', 'administration', 'expected', 'received', 'department', \n",
    "            'possible', 'together', 'republican', 'question']\n",
    "print('Frequency Distribution of Top 10 words whose character length in > 7 \\n')\n",
    "for top10 in topWords:\n",
    "    print(top10 + ':', inauguralFDist[top10], '\\n', end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
